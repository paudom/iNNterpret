# iNNterpret
iNNtrepret is an Interpretability Toolbox for Deep Learning Models. A project developed with the collaboration with UPC Image Processing Group. This Toolbox offers methods to help you interpret your NN models.

## Introduction
This was the product of a Degree Thesis submitted to the faculty of Escola Tècnica Superior d’Enginyeria de Telecomunicació de Barcelona Universitat Politècnica de Catalunya, with the title: "Interpretability of Deep Learning Models".  

Most of the times we evaluate models with the precision we get from a test database. But there are techniques that can allow us to comprehend better the decisions of our models. For the moment this Toolbox only works with VGG16 and is still in development.

## Version
1.1.0

## Acknowledgements
This ToolBox is inspired in "iNNvestigate", which I encourage to visit and try.
- [iNNvestigate](https://github.com/albermax/innvestigate). "iNNvestigate neural networks!" by Maximilian Alber, Sebastian Lapuschkin, Philipp Seegerer, Miriam Hägele, Kristof T. Schütt, Grégoire Montavon, Wojciech Samek, Klaus-Robert Müller, Sven Dähne, Pieter-Jan Kindermans. [Paper](http://arxiv.org/abs/1808.04260)
